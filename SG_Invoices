{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d78e40",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:26.106482Z",
     "iopub.status.busy": "2024-06-18T10:14:26.106197Z",
     "iopub.status.idle": "2024-06-18T10:14:26.857475Z",
     "shell.execute_reply": "2024-06-18T10:14:26.856414Z"
    },
    "papermill": {
     "duration": 0.758057,
     "end_time": "2024-06-18T10:14:26.859815",
     "exception": false,
     "start_time": "2024-06-18T10:14:26.101758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sg-invoicesocr/APPDATA - RESOLUTE SOLUTIONS PTE LTD - 24.05.24 - SGD267.05.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - Milkyway International - 20.03.2024 - SGD 446.80.pdf\n",
      "/kaggle/input/sg-invoicesocr/5140554566_Singapore_20240530025726.pdf\n",
      "/kaggle/input/sg-invoicesocr/2024000973_Singapore_20240402054647.pdf\n",
      "/kaggle/input/sg-invoicesocr/2400505 - INV ELITE_Singapore_20240401083404.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - HAYLEYS FREE ZONE LIMITED - 31.03.24 - USD2910.19.pdf\n",
      "/kaggle/input/sg-invoicesocr/62078749451.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - SAMUDERA SHIPPING LINE LTD - 27.03.24 - USD336.00.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - AIRMARK FREIGHT SERVICES PTE LTD - 12.03.24 - SGD240.87.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - WATERFRONT SERVICES PTE LTD - 04.04.24 - SGD978.95.pdf\n",
      "/kaggle/input/sg-invoicesocr/1275_001_Singapore_20240304070640.pdf\n",
      "/kaggle/input/sg-invoicesocr/0524_SINGTEL_MAY2024.pdf\n",
      "/kaggle/input/sg-invoicesocr/0966_001_Singapore_20240305031105.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - GEIS AIR + SEA GMBH - 08.02.24 - EUR1875.50.pdf\n",
      "/kaggle/input/sg-invoicesocr/7511378596_Singapore_20240502103827.pdf\n",
      "/kaggle/input/sg-invoicesocr/7505623153_Singapore_20240418030036.pdf\n",
      "/kaggle/input/sg-invoicesocr/413 3386187_Singapore_20240405021414.pdf\n",
      "/kaggle/input/sg-invoicesocr/52499933_Singapore_20240327111106.pdf\n",
      "/kaggle/input/sg-invoicesocr/9116064358_Singapore_20240205112313.pdf\n",
      "/kaggle/input/sg-invoicesocr/9116065839_Singapore_20240403102927.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - COSCO SHIPPING LINES (SINGAPORE) PTE LTD - 04.03.24 - SGD135.15.pdf\n",
      "/kaggle/input/sg-invoicesocr/5140554563_Singapore_20240530025735.pdf\n",
      "/kaggle/input/sg-invoicesocr/AI2405038_Singapore_20240513023758.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - CJ LOGISTICS ASIA PTE. LTD. - 30.04.24 - SGD359.70.pdf\n",
      "/kaggle/input/sg-invoicesocr/6201693738_Singapore_20240515102543.pdf\n",
      "/kaggle/input/sg-invoicesocr/001EA72391_Singapore_20240524100137.pdf\n",
      "/kaggle/input/sg-invoicesocr/001EA47367_Singapore_20240508094553.pdf\n",
      "/kaggle/input/sg-invoicesocr/2023006216_Singapore_20231206061914.pdf\n",
      "/kaggle/input/sg-invoicesocr/APPDATA - HAPAG-LLOYD PTE LTD - 30.03.24 - SGD155.00.pdf\n",
      "/kaggle/input/sg-invoicesocr/2400712 - INV ELITE_Singapore_20240510021415.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2b7f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:26.868537Z",
     "iopub.status.busy": "2024-06-18T10:14:26.867519Z",
     "iopub.status.idle": "2024-06-18T10:14:34.359407Z",
     "shell.execute_reply": "2024-06-18T10:14:34.358511Z"
    },
    "papermill": {
     "duration": 7.498316,
     "end_time": "2024-06-18T10:14:34.361590",
     "exception": false,
     "start_time": "2024-06-18T10:14:26.863274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libpoppler97 poppler-data\r\n",
      "Suggested packages:\r\n",
      "  ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\r\n",
      "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\r\n",
      "  fonts-arphic-uming fonts-nanum\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libpoppler97 poppler-data poppler-utils\r\n",
      "0 upgraded, 3 newly installed, 0 to remove and 75 not upgraded.\r\n",
      "Need to get 2564 kB of archives.\r\n",
      "After this operation, 16.8 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 poppler-data all 0.4.9-2 [1475 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpoppler97 amd64 0.86.1-0ubuntu1.4 [916 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.4 [174 kB]\r\n",
      "Fetched 2564 kB in 0s (9636 kB/s)\r\n",
      "Selecting previously unselected package poppler-data.\r\n",
      "(Reading database ... 113807 files and directories currently installed.)\r\n",
      "Preparing to unpack .../poppler-data_0.4.9-2_all.deb ...\r\n",
      "Unpacking poppler-data (0.4.9-2) ...\r\n",
      "Selecting previously unselected package libpoppler97:amd64.\r\n",
      "Preparing to unpack .../libpoppler97_0.86.1-0ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\r\n",
      "Selecting previously unselected package poppler-utils.\r\n",
      "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking poppler-utils (0.86.1-0ubuntu1.4) ...\r\n",
      "Setting up libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\r\n",
      "Setting up poppler-data (0.4.9-2) ...\r\n",
      "Setting up poppler-utils (0.86.1-0ubuntu1.4) ...\r\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.14) ...\r\n",
      "Processing triggers for man-db (2.9.1-1) ...\r\n",
      "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e816c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:34.375511Z",
     "iopub.status.busy": "2024-06-18T10:14:34.375201Z",
     "iopub.status.idle": "2024-06-18T10:14:58.773991Z",
     "shell.execute_reply": "2024-06-18T10:14:58.773193Z"
    },
    "papermill": {
     "duration": 24.408384,
     "end_time": "2024-06-18T10:14:58.776330",
     "exception": false,
     "start_time": "2024-06-18T10:14:34.367946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Directory containing the PDF invoices\n",
    "pdf_dir = '/kaggle/input/sg-invoicesocr'  # Update with your actual directory path\n",
    "# Directory to save images\n",
    "image_dir = '/kaggle/working/invoice_images'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Convert each PDF to images\n",
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    if pdf_file.endswith('.pdf'):\n",
    "        pages = convert_from_path(os.path.join(pdf_dir, pdf_file))\n",
    "        for i, page in enumerate(pages):\n",
    "            image_path = os.path.join(image_dir, f\"{os.path.splitext(pdf_file)[0]}_page_{i+1}.png\")\n",
    "            page.save(image_path, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad8bdee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:58.790312Z",
     "iopub.status.busy": "2024-06-18T10:14:58.790019Z",
     "iopub.status.idle": "2024-06-18T10:14:58.966605Z",
     "shell.execute_reply": "2024-06-18T10:14:58.965826Z"
    },
    "papermill": {
     "duration": 0.18588,
     "end_time": "2024-06-18T10:14:58.968815",
     "exception": false,
     "start_time": "2024-06-18T10:14:58.782935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0301ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:58.982171Z",
     "iopub.status.busy": "2024-06-18T10:14:58.981924Z",
     "iopub.status.idle": "2024-06-18T10:14:58.989227Z",
     "shell.execute_reply": "2024-06-18T10:14:58.988550Z"
    },
    "papermill": {
     "duration": 0.016162,
     "end_time": "2024-06-18T10:14:58.991051",
     "exception": false,
     "start_time": "2024-06-18T10:14:58.974889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "def perform_ocr(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0d5c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:59.004256Z",
     "iopub.status.busy": "2024-06-18T10:14:59.003994Z",
     "iopub.status.idle": "2024-06-18T10:14:59.009438Z",
     "shell.execute_reply": "2024-06-18T10:14:59.008649Z"
    },
    "papermill": {
     "duration": 0.014131,
     "end_time": "2024-06-18T10:14:59.011271",
     "exception": false,
     "start_time": "2024-06-18T10:14:58.997140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_details(text):\n",
    "    # Regex for company name (assuming it's a word starting with a capital letter)\n",
    "    company_pattern = r'\\b[A-Z][a-zA-Z]+(?:\\s+[A-Z][a-zA-Z]+)*\\b'\n",
    "    # Regex for total cost (assuming currency symbols like $, €, £, etc.)\n",
    "    cost_pattern = r'\\b(?:USD|EUR|GBP|AUD|CAD|CHF|CNY|JPY|INR|RUB|SGD)?\\s?[\\$€£¥]?\\s?\\d+(?:,\\d{3})*(?:\\.\\d{2})?\\b'\n",
    "    \n",
    "    company = re.findall(company_pattern, text)\n",
    "    total_cost = re.findall(cost_pattern, text)\n",
    "    \n",
    "    return {\n",
    "        'company': company[0] if company else None,\n",
    "        'total_cost': total_cost[0] if total_cost else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5433e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T10:14:59.024450Z",
     "iopub.status.busy": "2024-06-18T10:14:59.024024Z",
     "iopub.status.idle": "2024-06-18T10:17:49.061722Z",
     "shell.execute_reply": "2024-06-18T10:17:49.060746Z"
    },
    "papermill": {
     "duration": 170.052734,
     "end_time": "2024-06-18T10:17:49.069989",
     "exception": false,
     "start_time": "2024-06-18T10:14:59.017255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                              company   total_cost\n",
      "0                                      WAN HAI\\n\\nDST            6\n",
      "1            BRAG SCS\\n\\nLeschaco Pte Ltd\\n\\nPan Thee       608526\n",
      "2   MAERSK\\n\\nEQUIPMENT MAINTENANCE INVOICE\\n\\nCus...        \\n\\n1\n",
      "3                                 RAE\\n\\nOcean Vessel          329\n",
      "4   MAERSK\\n\\nCustomer\\n\\nSYNGENTA ASIA PACIFIC PT...         2010\n",
      "..                                                ...          ...\n",
      "56                                            Pm Tier           31\n",
      "57                                    HEPC Account No     96463548\n",
      "58                      PROFORMA TAX INVOICE\\nGST REG      0121206\n",
      "59                               JING ET\\n\\nLogistics   5140554563\n",
      "60                                              Datum           79\n",
      "\n",
      "[61 rows x 2 columns]\n",
      "\n",
      "Saved CSV file to: /kaggle/working/invoice_details.csv\n",
      "Saved JSON file to: /kaggle/working/invoice_details.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Perform OCR and extract details for each image\n",
    "for image_file in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    text = perform_ocr(image_path)\n",
    "    details = extract_details(text)\n",
    "    results.append(details)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Save results to CSV\n",
    "csv_path = '/kaggle/working/invoice_details.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nSaved CSV file to: {csv_path}\")\n",
    "\n",
    "# Save results to JSON\n",
    "json_path = '/kaggle/working/invoice_details.json'\n",
    "df.to_json(json_path, orient='records', lines=True)\n",
    "print(f\"Saved JSON file to: {json_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5231856,
     "sourceId": 8719401,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 206.173037,
   "end_time": "2024-06-18T10:17:49.494877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-18T10:14:23.321840",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
